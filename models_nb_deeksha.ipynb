{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as local_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import pytorch_utils\n",
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from importlib import reload\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils, models\n",
    "import os, sys\n",
    "from random import shuffle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have an option to **use GPU by setting the flag to True below**. It is not necessary to use GPU for this assignment. Note that if your computer does not have CUDA enabled, `torch.cuda.is_available()` will return False and this notebook will fallback to CPU mode.\n",
    "\n",
    "The global variables `dtype` and `device` will control the data types throughout this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "IMG_SZ = 224\n",
    "#IMG_SZ = 32\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(src_folder, num_classes, num_per_class):\n",
    "    '''\n",
    "    returns a list of filenames for num_classes and num_per_class images per class\n",
    "    '''\n",
    "    src_files = [f for f in os.listdir(src_folder) if os.path.isfile(os.path.join(src_folder, f)) \n",
    "                 and f != '.DS_Store']\n",
    "    \n",
    "    hist = [0] * num_classes\n",
    "    \n",
    "    res_files = []\n",
    "    \n",
    "    for f in src_files:\n",
    "        label = int(f[f.index('_') + 1 : f.index('.')]) # filename format: [id_label.jpg]\n",
    "        if label >= num_classes: continue\n",
    "        if hist[label] < num_per_class:\n",
    "            res_files.append(f)\n",
    "            hist[label] += 1\n",
    "            \n",
    "        if sum(hist) == num_classes * num_per_class:\n",
    "            break\n",
    "            \n",
    "    shuffle(res_files)  # shuffles in place\n",
    "    \n",
    "    return res_files\n",
    "\n",
    "# test implementation\n",
    "# src_folder = '../data/data_100c/train'\n",
    "# src_files = get_files(src_folder, num_classes=100, num_per_class=200)\n",
    "# print (len(src_files))\n",
    "# print (src_files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(infilename):\n",
    "    '''\n",
    "    opens image at provided path, returns numpy array \n",
    "    https://stackoverflow.com/questions/7762948/how-to-convert-an-rgb-image-to-numpy-array\n",
    "    '''\n",
    "    img = Image.open(infilename)\n",
    "    img.load()\n",
    "    #data = np.asarray( img, dtype=\"int32\" )\n",
    "    data = np.asarray(img, dtype='uint8')\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_data(src_folder, num_classes, num_per_class):\n",
    "    src_files = get_files(src_folder, num_classes, num_per_class)\n",
    "\n",
    "    # this is if we know how much to load in advance\n",
    "    NUM_TO_LOAD = num_classes * num_per_class\n",
    "    estimated_N = NUM_TO_LOAD\n",
    "    X, Y = np.empty([estimated_N, IMG_SZ, IMG_SZ, 3]), np.empty([estimated_N])\n",
    "\n",
    "    position = 0\n",
    "    for i in range(len(src_files)):\n",
    "        _file = src_files[i]\n",
    "        x = load_image(src_folder + '/' + _file)  # numpy array [IMG_SZ x IMG_SZ x 3]\n",
    "    \n",
    "        y = _file[_file.index('_') + 1 : _file.index('.')]  # filename format: [id_label.jpg]\n",
    "        \n",
    "        X[position] = x\n",
    "        Y[position] = y\n",
    "        position = position + 1\n",
    "\n",
    "        if i % (1000) == 0: print ('i', i)\n",
    "        \n",
    "    X = X[:position]\n",
    "    Y = Y[:position]\n",
    "    \n",
    "    # normalizing the data to be between 0 and 1\n",
    "    print ('normalizing data')\n",
    "    \n",
    "    # normalizing the data by the mean and std dev that https://pytorch.org/docs/master/torchvision/models.html asks for\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    v_min = X.min(axis=(0, 1, 2), keepdims=True)\n",
    "    v_max = X.max(axis=(0, 1, 2), keepdims=True)\n",
    "    print(v_min.shape)\n",
    "#     X = np.subtract(X, v_min)\n",
    "#     X = np.divide(X, np.subtract(v_max, v_min))\n",
    "#     X = np.divide(np.subtract(X-mean), std)\n",
    "    for num in range(3):\n",
    "        print(num)\n",
    "        X[:,:,:,num] = X[:,:,:,num] - v_min[:,:,:,num]\n",
    "        temp = v_max[:,:,:,num] - v_min[:,:,:,num]\n",
    "        X[:,:,:,num] = X[:,:,:,num] / temp\n",
    "        X[:,:,:,num] = X[:,:,:,num] - mean[num]\n",
    "        X[:,:,:,num] = X[:,:,:,num] / std[num]\n",
    "    print ('load_data returning X', X.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(X, Y, batch_size):\n",
    "    values = DataLoader.TensorDataset(torch.from_numpy(X), torch.from_numpy(Y))\n",
    "    loader_values = DataLoader.DataLoader(dataset=values,\n",
    "        batch_size = batch_size)\n",
    "    return loader_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "def random_weight(shape):\n",
    "    \"\"\"\n",
    "    Create random Tensors for weights; setting requires_grad=True means that we\n",
    "    want to compute gradients for these Tensors during the backward pass.\n",
    "    We use Kaiming normalization: sqrt(2 / fan_in)\n",
    "    \"\"\"\n",
    "    if len(shape) == 2:  # FC weight\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n",
    "    # randn is standard normal distribution generator. \n",
    "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
    "    w.requires_grad = True\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    # if loader.dataset.train:\n",
    "    #     print('Checking accuracy on validation set')\n",
    "    # else:\n",
    "    #     print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for t, (x, y) in enumerate(loader):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loader_train, epochs=1, stop=1):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    iters = []\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        print ('epoch', e)\n",
    "        \n",
    "        num_iters = len(loader_train)\n",
    "        want_print = 10\n",
    "        print_every = 50\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "        \n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print(' Iteration %d out of %d, loss = %.4f' % (t, num_iters, loss.item()))\n",
    "                iters.append(t)\n",
    "                losses.append(loss.item())\n",
    "            \n",
    "            # break early if we only want to use a part of the dataset (for hyperparameter tuning)\n",
    "            if t > stop * num_iters:\n",
    "                break\n",
    "\n",
    "    return iters, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional layer with channel_1 5x5 filters with zero-padding of 2\n",
    "# ReLU\n",
    "# Fully-connected layer to num_classes classes\n",
    "class TwoLayerConvNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, num_classes, filter_size, zero_padding):\n",
    "        super(TwoLayerConvNet, self).__init__()\n",
    "        self.conv_w1 = nn.Conv2d(in_channel, channel_1, filter_size, 1, (zero_padding,zero_padding))\n",
    "        nn.init.kaiming_normal_(self.conv_w1.weight)\n",
    "        self.fc1 = nn.Linear(channel_1*IMG_SZ*IMG_SZ, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        x = F.relu(self.conv_w1(x))\n",
    "        x = flatten(x)\n",
    "        scores = self.fc1(x)\n",
    "        return scores\n",
    "\n",
    "class TwoLayerFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(TwoLayerFC, self).__init__()\n",
    "        # assign layer objects to class attributes\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # nn.init package contains convenient initialization methods\n",
    "        # http://pytorch.org/docs/master/nn.html#torch-nn-init \n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward always defines connectivity\n",
    "        x = flatten(x)\n",
    "        scores = self.fc2(F.relu(self.fc1(x)))\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runFC(hidden_layer_size, num_classes):\n",
    "    return TwoLayerFC(3 * IMG_SZ * IMG_SZ, hidden_layer_size, num_classes)\n",
    "\n",
    "def runTwoLayerCNN(num_classes):\n",
    "    num_channels = 10\n",
    "    return TwoLayerConvNet(3, num_channels, num_classes, 5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoaderData(directory, batch_size,  num_classes, num_per_class):\n",
    "    X, Y = load_data(directory, num_classes, num_per_class)\n",
    "    N = X.shape[0]\n",
    "\n",
    "    # previously, X is: N x 256 x 256 x 3 ; make channels second\n",
    "    X = np.transpose(X, (0, 3, 1, 2))  # N x 3 x 256 x 256\n",
    "\n",
    "    num_classes = len(set(Y))\n",
    "    # training_portion = 1\n",
    "    # num_train = int(N * training_portion)\n",
    "\n",
    "    loader_data = loadData(X, Y, batch_size)\n",
    "\n",
    "    print ('x', X.shape)\n",
    "    print ('y', Y[:5])\n",
    "    print ('num_classes', num_classes)\n",
    "    return loader_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loads the training data\n",
    "loader_train = getLoaderData('../data/data_200c/train', 50, 200, 150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train / val plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "def show(img):\n",
    "    npimg = img.numpy().astype(dtype='uint8')\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "\n",
    "for t, (x, y) in enumerate(loader_train):\n",
    "    for i in range(2):\n",
    "        yi = y[i]\n",
    "        img = x[i]\n",
    "        show(img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = '../data/data_100c/train/'\n",
    "src_files = [f for f in os.listdir(src_folder) if os.path.isfile(os.path.join(src_folder, f)) and f != '.DS_Store']\n",
    "\n",
    "nRows = 3\n",
    "nCols = 5\n",
    "\n",
    "f, axarr = plt.subplots(nRows, nCols)\n",
    "\n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "n = 0\n",
    "for i in range(nRows):\n",
    "    for j in range(nCols):\n",
    "        img = PIL.Image.open(src_folder + src_files[n])\n",
    "        axarr[i, j].imshow(img)\n",
    "        #axarr[i, j].axis('off')\n",
    "        n += 1\n",
    "\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(pytorch_utils)\n",
    "pytorch_utils.hi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 300\n",
    "learning_rates = [0.0000001,0.00001, 0.001, 0.1]\n",
    "training_portion = 0.8\n",
    "num_epochs = 10\n",
    "\n",
    "print(\"Num classes is \", num_classes)\n",
    "print(\"Num samples being considered in training is \", num_train)\n",
    "print(\"Num samples in val is \", N - num_train)\n",
    "print(\"hidden_layer_size is \", hidden_layer_size)\n",
    "print(\"batch_size is \", batch_size)\n",
    "\n",
    "model = runTwoLayerCNN(num_classes)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.5)\n",
    "# acc = train(model, optimizer, loader_train, loader_val, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to wrap `flatten` function in a module in order to stack it\n",
    "# in nn.Sequential\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "    \n",
    "learning_rate = 1e-2\n",
    "\n",
    "num_hidden = 50000\n",
    "model = nn.Sequential(\n",
    "    # input is C x H x W\n",
    "    \n",
    "    # Two conv layers, 64 filters, and pooling\n",
    "    nn.Conv2d(3, 64, 3, padding=1),    # 64 x H x W\n",
    "    nn.ReLU(),                         # 64 x H x W\n",
    "    # Batch normalization              # 64 x H x W\n",
    "    nn.Conv2d(64, 64, 3, padding=1),   # 64 x H x W\n",
    "    # RESIDUAL                         # 64 x H x W\n",
    "    nn.ReLU(),                         # 64 x H x W\n",
    "    # Batch normalization              # 64 x H x W\n",
    "    nn.MaxPool2d(2),                   # 64 x H/2 x W/2\n",
    "    # INCEPTION\n",
    "    \n",
    "    # Two conv layers, 128 filters, and pooling\n",
    "    nn.Conv2d(64, 128, 3, padding=1),  # 128 x H/2 x W/2\n",
    "    nn.ReLU(),                         # 128 x H/2 x W/2\n",
    "    # Batch normalization              # 128 x H/2 x W/2\n",
    "    nn.Conv2d(128, 128, 3, padding=1), # 128 x H/2 x W/2\n",
    "    # RESIDUAL                         # 128 x H/2 x W/2\n",
    "    nn.ReLU(),                         # 128 x H/2 x W/2\n",
    "    # Batch normalization              # 128 x H/2 x W/2\n",
    "    nn.MaxPool2d(2),                   # 128 x H/4 x W/4\n",
    "    # INCEPTION                        \n",
    "    \n",
    "    # Two conv layers, 256 filters, and pooling\n",
    "    nn.Conv2d(128, 256, 3, padding=1), # 256 x H/4 x W/4\n",
    "    nn.ReLU(),                         # 256 x H/4 x W/4\n",
    "    # Batch normalization              # 256 x H/4 x W/4\n",
    "    nn.Conv2d(256, 256, 3, padding=1), # 256 x H/4 x W/4\n",
    "    # RESIDUAL                         # 256 x H/4 x W/4\n",
    "    nn.ReLU(),                         # 256 x H/4 x W/4\n",
    "    # Batch normalization              # 256 x H/4 x W/4\n",
    "    nn.MaxPool2d(2),                   # 256 x H/8 x W/8\n",
    "    # INCEPTION\n",
    "    \n",
    "    Flatten(),\n",
    "    nn.Linear(256 * 28 * 28, num_hidden),\n",
    "    nn.Linear(num_hidden, num_classes),\n",
    ")\n",
    "\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "\n",
    "#acc = train(model, optimizer, loader_train, loader_val, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getLoaderData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0b49e87a853b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbest_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mloader_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLoaderData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/data_200c/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlr_vals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getLoaderData' is not defined"
     ]
    }
   ],
   "source": [
    "# resnet\n",
    "# https://www.kaggle.com/gntoni/using-pytorch-resnet\n",
    "\n",
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225])\n",
    "\n",
    "plotting_data = []\n",
    "\n",
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "lr_vals = [0.0001, 0.001, 0.01]\n",
    "momentum = 0.9\n",
    "batch_sizes = [10, 20, 50, 80]\n",
    "best_lr = None\n",
    "best_batch_size = None\n",
    "for batch_size in batch_sizes:\n",
    "    loader_train = getLoaderData('../data/data_200c/train', batch_size, 200, 150)\n",
    "    for lr in lr_vals:\n",
    "        model = models.resnet18(pretrained=True)  # 18\n",
    "        \n",
    "        \n",
    "        # Observe that all parameters are being optimized\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        num_epochs = 1\n",
    "        iters, losses = train(model, optimizer, loader_train, num_epochs, 0.20) #stopping early to save time\n",
    "        \n",
    "        s = 'lr: %f, batch sz: %d' % (lr, batch_size)\n",
    "        plotting_data.append((iters, losses, s))\n",
    "        \n",
    "        final_loss = losses[-1]\n",
    "        print('got a loss of ', final_loss, ' for parameters ', 'batch size: ', batch_size, ' lr: ', lr)\n",
    "        if final_loss < best_loss:\n",
    "            best_loss = final_loss\n",
    "            best_model = model\n",
    "            best_lr = lr\n",
    "            best_batch_size = batch_size\n",
    "print(\"best values \", best_loss, best_lr, best_batch_size)\n",
    "\n",
    "val_acc = check_accuracy(loader_val, best_model)\n",
    "print ('validation accuracy is ', val_acc)\n",
    "train_acc = check_accuracy(loader_train, best_model)\n",
    "print ('training accuracy is ', train_acc)\n",
    "\n",
    "for plot_data in plotting_data:\n",
    "    iters, losses, label = plot_data\n",
    "    plt.plot(iters, losses, label=label)\n",
    "plt.title('Loss for different hyperparameters')\n",
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loads the validation data\n",
    "\n",
    "loader_val = getLoaderData('../data/data_200c/val', best_batch_size, 200, 40)\n",
    "print ('validation accuracy')\n",
    "val_acc = check_accuracy(loader_val, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot based on acc_data object\n",
    "\n",
    "# final_train_acc = acc_data['train_accs']\n",
    "# val_accs = acc_data['val_accs']\n",
    "# iterations = acc_data['iters']\n",
    "\n",
    "val_accs = [4.6414, 4.2146, 3.6606, 3.0006, 2.5316, 2.0794, 1.8258, 1.6168]\n",
    "# final_train_acc = 71.14\n",
    "iterations = [0, 50, 100, 150, 200, 250, 300, 315]\n",
    "\n",
    "# plot\n",
    "plt.plot(iterations, val_accs, label='validation accuracy')\n",
    "plt.title('resnet152 on 16K train, 4K val')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting val / train accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is hardcoded for the first run\n",
    "train_acc = [1.92, 3.07, 4.01, 9.02, 16.16, 23.79, 32.23, 33.89]\n",
    "val_acc =   [2.20, 3.08, 3.84, 8.56, 14.73, 21.27, 28.89, 30.90]\n",
    "iterations = [0, 5, 10, 15, 20, 25, 30, 31]\n",
    "\n",
    "# plot\n",
    "plt.plot(iterations, train_acc, label='train accuracy')\n",
    "plt.plot(iterations, val_acc, label='validation accuracy')\n",
    "plt.title('resnet152 on 6.4K train, 1.6K val')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we see that there is a small gap between train and val, so the model does not seem to be overfitting too much. Also, it seems like the accuracy is increasing almost linearly, indicating that training for more epochs would improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg\n",
    "model = models.vgg11(pretrained=True)\n",
    "\n",
    "# https://medium.com/@14prakash/almost-any-image-classification-problem-using-pytorch-i-am-in-love-with-pytorch-26c7aa979ec4\n",
    "# Number of filters in the bottleneck layer\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "# convert all the layers to list and remove the last one\n",
    "features = list(model.classifier.children())[:-1]\n",
    "## Add the last layer based on the num of classes in our dataset\n",
    "features.extend([nn.Linear(num_ftrs, num_classes)])\n",
    "## convert it into container and add it to our model class.\n",
    "model.classifier = nn.Sequential(*features)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "acc = train(model, optimizer, loader_train, loader_val, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
