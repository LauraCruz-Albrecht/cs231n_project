{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as local_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import pytorch_utils\n",
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from importlib import reload\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils, models\n",
    "import os, sys\n",
    "from random import shuffle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "IMG_SZ = 224\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarksDataset(DataLoader.Dataset):\n",
    "\n",
    "    def __init__(self, src_folder, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src_folder (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.filenames = [f for f in os.listdir(src_folder) if os.path.isfile(os.path.join(src_folder, f)) \n",
    "                          and f != '.DS_Store']\n",
    "        self.src_folder = src_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.src_folder, self.filenames[idx])\n",
    "        \n",
    "        x = Image.open(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        imgf = self.filenames[idx]\n",
    "        y = int(imgf[imgf.index('_') + 1 : imgf.index('.')]) # filename format: [id_label.jpg]\n",
    "        sample = (x, y)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(directory, batch_size):\n",
    "    '''\n",
    "    takes in directory for train and val data, and returns loaders for both\n",
    "    applies normalization:\n",
    "      1. convert values to range 0-1\n",
    "      2. set mean, std to those specified in pytorch pretrained models (https://pytorch.org/docs/master/torchvision/models.html)\n",
    "    \n",
    "    usage:\n",
    "        loader_train = get_loader(train_directory, batch_sz)\n",
    "        loader_val = get_loader(val_directory, batch_sz)\n",
    "    '''\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                      std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "       transforms.ToTensor(),  # converts to range 0-1\n",
    "       normalize               # sets mean, std\n",
    "    ])\n",
    "    \n",
    "    dset = LandmarksDataset(directory, transform=preprocess)\n",
    "    loader = DataLoader.DataLoader(dataset=dset, batch_size=batch_size)\n",
    "    \n",
    "    print ('dataset size', len(dset))\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and accuracy checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model): \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for t, (x, y) in enumerate(loader):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loader_train, epochs=1, stop=1):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    iters = []\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        print ('epoch', e)\n",
    "        \n",
    "        num_iters = len(loader_train)\n",
    "        want_print = 10\n",
    "        print_every = 50\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "        \n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print(' Iteration %d out of %d, loss = %.4f' % (t, num_iters, loss.item()))\n",
    "                iters.append(t)\n",
    "                losses.append(loss.item())\n",
    "            \n",
    "            # break early if we only want to use a part of the dataset (for hyperparameter tuning)\n",
    "            if t > stop * num_iters:\n",
    "                break\n",
    "\n",
    "    return iters, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_data(plotting_data, title_str):\n",
    "    '''\n",
    "    Plots all loss curves for hyperparameter tuning runs.\n",
    "    Plots loss vs. iterations.\n",
    "    '''\n",
    "    for plot_data in plotting_data:\n",
    "        iters, losses, label = plot_data        \n",
    "        plt.plot(iters, losses, label=label)\n",
    "    plt.title(title_str)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=(1.1, 0.25))\n",
    "    \n",
    "    # set figsize\n",
    "    plt.rcParams[\"figure.figsize\"] = (9, 6)\n",
    "    \n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_data_v2(plotting_data, title_str):\n",
    "    '''\n",
    "    Plots all loss curves for hyperparameter tuning runs\n",
    "    This version plots loss vs. percent of iterations complete. This means\n",
    "    each run has the same x distance on the graph.\n",
    "    '''\n",
    "    max_n = max([len(iters) for iters, _, _ in plotting_data])\n",
    "    \n",
    "    for plot_data in plotting_data:\n",
    "        iters, losses, label = plot_data \n",
    "        n = len(losses)\n",
    "        \n",
    "        # need to go between 0 and max_n, with n entries\n",
    "        dist = (max_n - 1) / (n-1)\n",
    "        x = [e * dist for e in range(n)]\n",
    "        x_max = max(x)\n",
    "        x = [e / x_max for e in x] # normalize to 0 - 1\n",
    "                \n",
    "        plt.plot(x, losses, label=label)\n",
    "        \n",
    "    plt.title(title_str)\n",
    "    plt.xlabel('Fraction of tuning run elapsed')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=(1.1, 0.25))\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (9, 6) # set figsize\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca53d38278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "iters = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1520]\n",
    "losses = [5.2103 , 5.2902, 5.3339 , 4.8820 , 4.9131 , 4.7288, 4.8663 , 4.5275, 4.9398, 4.6526, 4.8179, 5.0909, 4.8937, 4.5543,4.4313,4.0155, 4.01549768447876    ]\n",
    "plot_single_loss(iters, losses, \"Loss for tuned custom model\")\n",
    "def plot_single_loss(iters, losses, title_str):\n",
    "    plt.plot(iters, losses)\n",
    "    plt.title(title_str)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    # set figsize\n",
    "    plt.rcParams[\"figure.figsize\"] = (9, 6)\n",
    "    \n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 30395\n",
      "epoch 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9f25ecc6c33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# stopping early to save time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lr: %f, batch sz: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-374feb2e3338>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loader_train, epochs, stop)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mthreshold\u001b[0;34m(input, threshold, value, inplace)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \"\"\"\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# referenced https://www.kaggle.com/gntoni/using-pytorch-resnet\n",
    "\n",
    "# hyperparam tuning on lr and batch sz\n",
    "lr_vals = [0.0001, 0.001, 0.01]\n",
    "# batch_sizes = [10, 20, 50, 80]\n",
    "batch_sizes = [80]\n",
    "\n",
    "train_directory = '../data/data_200c/train'\n",
    "val_directory = '../data/data_200c/val'\n",
    "\n",
    "momentum = 0.9\n",
    "num_classes = 200\n",
    "\n",
    "best_lr = None\n",
    "best_batch_size = None\n",
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "plotting_data = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    loader_train = get_loader(train_directory, batch_size)\n",
    "    for lr in lr_vals:\n",
    "        # set up resnet model with custom FC layer to predict our number of classes\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "        # Observe that all parameters are being optimized\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        num_epochs = 1\n",
    "        iters, losses = train(model, optimizer, loader_train, num_epochs, 0.20) # stopping early to save time\n",
    "        \n",
    "        s = 'lr: %f, batch sz: %d' % (lr, batch_size)\n",
    "        plotting_data.append((iters, losses, s))\n",
    "        \n",
    "        final_loss = losses[-1]\n",
    "        print('got a loss of ', final_loss, ' for parameters ', 'batch size: ', batch_size, ' lr: ', lr)\n",
    "        if final_loss < best_loss:\n",
    "            best_loss = final_loss\n",
    "            best_model = model\n",
    "            best_lr = lr\n",
    "            best_batch_size = batch_size\n",
    "            \n",
    "print(\"best values \", best_loss, best_lr, best_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best_lr, best_batch_size\n",
    "lr = best_lr\n",
    "batch_size = best_batch_size\n",
    "\n",
    "# load data\n",
    "loader_val = get_loader(val_directory, batch_size)\n",
    "loader_train = get_loader(train_directory, batch_size)\n",
    "\n",
    "# set up squeezenet model with custom final conv layer to predict our number of classes\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# run for full epoch\n",
    "num_epochs = 1\n",
    "iters, losses = train(model, optimizer, loader_train, num_epochs)\n",
    "\n",
    "# get final accuracies\n",
    "print ('validation accuracy is ', check_accuracy(loader_val, model))\n",
    "print ('training accuracy is ', check_accuracy(loader_train, model))\n",
    "\n",
    "# plot loss for fully trained best model\n",
    "plot_single_loss(iters, losses, 'Loss for tuned Resnet18 model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(plotting_data, title_str=\"Hyperparameter tuning for Resnet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_data_v2(plotting_data, title_str=\"Hyperparameter tuning for Resnet18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL NET!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 30395\n",
      "epoch 0\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      " Iteration 0 out of 3040, loss = 5.2462\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      " Iteration 5 out of 3040, loss = 5.2405\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      " Iteration 10 out of 3040, loss = 5.2337\n",
      "Finished a DL block\n",
      "Finished an inception block\n",
      "Finished a DL block\n",
      "Finished an inception block\n"
     ]
    }
   ],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "    \n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "    \n",
    "class InceptionModule(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 32, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = BasicConv2d(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = BasicConv2d(48, 32, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = BasicConv2d(96, 32, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = BasicConv2d(in_channels, out_channels-3*32, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "#         print(\"Finished an inception block\")\n",
    "        return torch.cat(outputs, 1)    \n",
    "    \n",
    "class DLNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, filter_size=3, padding=1, pool_size=2):\n",
    "        super(DLNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, filter_size, padding=padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, filter_size, padding=padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.pool = nn.MaxPool2d(pool_size)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        \n",
    "        out = self.relu2(out)\n",
    "        out = self.pool(out)\n",
    "        \n",
    "#         print(\"Finished a DL block\")\n",
    "        return out\n",
    "\n",
    "\n",
    "num_hidden = 400\n",
    "momentum = 0.9\n",
    "num_classes = 200\n",
    "\n",
    "# hyperparam tuning on lr and batch sz\n",
    "lr_vals = [0.0001, 0.001, 0.01]\n",
    "batch_sizes = [10, 20, 50, 80]\n",
    "\n",
    "train_directory = '../data/data_200c/train'\n",
    "val_directory = '../data/data_200c/val'\n",
    "\n",
    "best_lr = None\n",
    "best_batch_size = None\n",
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "plotting_data = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    loader_train = get_loader(train_directory, batch_size)\n",
    "    for lr in lr_vals:\n",
    "        model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            DLNetBlock(64, 64),\n",
    "            nn.Dropout(),\n",
    "            InceptionModule(64, 128),\n",
    "            nn.Dropout(),\n",
    "            DLNetBlock(128, 128),\n",
    "            nn.Dropout(),\n",
    "            InceptionModule(128, 256),\n",
    "            nn.Dropout(),\n",
    "            DLNetBlock(256, 256),\n",
    "\n",
    "            # added these layers here so that the following linear layer does not have too many parameters and crash\n",
    "            nn.Conv2d(256, 3, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            Flatten(),\n",
    "            nn.Linear(3 * 14 * 14, num_hidden),\n",
    "            nn.Linear(num_hidden, num_classes),\n",
    "        )\n",
    "        \n",
    "        # Observe that all parameters are being optimized\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "        \n",
    "        num_epochs = 1\n",
    "        iters, losses = train(model, optimizer, loader_train, num_epochs, 0.20) # stopping early to save time\n",
    "        \n",
    "        s = 'lr: %f, batch sz: %d' % (lr, batch_size)\n",
    "        plotting_data.append((iters, losses, s))\n",
    "        \n",
    "        final_loss = losses[-1]\n",
    "        print('got a loss of ', final_loss, ' for parameters ', 'batch size: ', batch_size, ' lr: ', lr)\n",
    "        if final_loss < best_loss:\n",
    "            best_loss = final_loss\n",
    "            best_model = model\n",
    "            best_lr = lr\n",
    "            best_batch_size = batch_size\n",
    "            \n",
    "print(\"best values \", best_loss, best_lr, best_batch_size)\n",
    "# get final accuracies\n",
    "print ('validation accuracy is ', check_accuracy(loader_val, best_model))\n",
    "print ('training accuracy is ', check_accuracy(loader_train, best_model))\n",
    "\n",
    "# plot loss for fully trained best model\n",
    "plot_single_loss(iters, losses, 'Loss for tuned custom model')\n",
    "plot_loss_data_v2(plotting_data, title_str=\"Hyperparameter tuning for Custom Net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparam tuning on lr and batch sz\n",
    "lr_vals = [0.0001, 0.001, 0.01]\n",
    "batch_sizes = [10, 20, 50, 80]\n",
    "\n",
    "train_directory = '../data/data_200c/train'\n",
    "val_directory = '../data/data_200c/val'\n",
    "\n",
    "# for testing\n",
    "# train_directory = '../data/data_200c/mini'\n",
    "# val_directory = '../data/data_200c/mini'\n",
    "# batch_sizes = [1, 2, 5, 8]\n",
    "\n",
    "momentum = 0.9\n",
    "num_classes = 200\n",
    "\n",
    "best_lr = None\n",
    "best_batch_size = None\n",
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "plotting_data = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    loader_train = get_loader(train_directory, batch_size)\n",
    "    for lr in lr_vals:\n",
    "        # set up squeezenet model with custom final conv layer to predict our number of classes\n",
    "        model = models.squeezenet1_0(pretrained=True)\n",
    "        final_conv = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        model.num_classes = num_classes\n",
    "        model.classifier = nn.Sequential(\n",
    "                    nn.Dropout(p=0.5),\n",
    "                    final_conv,\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.AvgPool2d(13))\n",
    "        \n",
    "        # Observe that all parameters are being optimized\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        num_epochs = 1\n",
    "        iters, losses = train(model, optimizer, loader_train, num_epochs, 0.20) # stopping early to save time\n",
    "        \n",
    "        s = 'lr: %f, batch sz: %d' % (lr, batch_size)\n",
    "        plotting_data.append((iters, losses, s))\n",
    "        \n",
    "        final_loss = losses[-1]\n",
    "        print('got a loss of ', final_loss, ' for parameters ', 'batch size: ', batch_size, ' lr: ', lr)\n",
    "        if final_loss < best_loss:\n",
    "            best_loss = final_loss\n",
    "            best_model = model\n",
    "            best_lr = lr\n",
    "            best_batch_size = batch_size\n",
    "print (' ')          \n",
    "print(\"best loss: \", best_loss, 'best lr', best_lr, 'best batch sz', best_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss curves for hyperparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_data(plotting_data, title_str=\"Hyperparameter tuning for Squeezenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_data_v2(plotting_data, title_str=\"Hyperparameter tuning for Squeezenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train best model for full epoch, get final val & train accuracy, plot loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best_lr, best_batch_size\n",
    "lr = best_lr\n",
    "batch_size = best_batch_size\n",
    "\n",
    "# load data\n",
    "loader_val = get_loader(val_directory, batch_size)\n",
    "loader_train = get_loader(train_directory, batch_size)\n",
    "\n",
    "# set up squeezenet model with custom final conv layer to predict our number of classes\n",
    "model = models.squeezenet1_0(pretrained=True)\n",
    "final_conv = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "model.num_classes = num_classes\n",
    "model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            final_conv,\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(13))\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# run for full epoch\n",
    "num_epochs = 1\n",
    "iters, losses = train(model, optimizer, loader_train, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final accuracies\n",
    "print ('validation accuracy is ', check_accuracy(loader_val, model))\n",
    "print ('training accuracy is ', check_accuracy(loader_train, model))\n",
    "\n",
    "# plot loss for fully trained best model\n",
    "plot_single_loss(iters, losses, 'Loss for tuned Squeezenet model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss for fully trained best model\n",
    "plot_single_loss(iters, losses, 'Loss for tuned Squeezenet model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparam tuning on lr and batch sz\n",
    "lr_vals = [0.0001, 0.001, 0.01]\n",
    "batch_sizes = [10, 20, 50, 80]\n",
    "\n",
    "train_directory = '../data/data_200c/train'\n",
    "val_directory = '../data/data_200c/val'\n",
    "\n",
    "# for testing\n",
    "# train_directory = '../data/data_200c/mini'\n",
    "# val_directory = '../data/data_200c/mini'\n",
    "# batch_sizes = [1, 2, 5, 8]\n",
    "\n",
    "momentum = 0.9\n",
    "num_classes = 200\n",
    "\n",
    "best_lr = None\n",
    "best_batch_size = None\n",
    "best_model = None\n",
    "best_loss = float('inf')\n",
    "plotting_data = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    loader_train = get_loader(train_directory, batch_size)\n",
    "    for lr in lr_vals:\n",
    "        # set up inception model with custom final FC layer to predict our number of classes\n",
    "        model = models.inception_v3(pretrained=True)\n",
    "        model.aux_logit=False\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "        # Observe that all parameters are being optimized\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        num_epochs = 1\n",
    "        iters, losses = train(model, optimizer, loader_train, num_epochs, 0.20) # stopping early to save time\n",
    "        \n",
    "        s = 'lr: %f, batch sz: %d' % (lr, batch_size)\n",
    "        plotting_data.append((iters, losses, s))\n",
    "        \n",
    "        final_loss = losses[-1]\n",
    "        print('got a loss of ', final_loss, ' for parameters ', 'batch size: ', batch_size, ' lr: ', lr)\n",
    "        if final_loss < best_loss:\n",
    "            best_loss = final_loss\n",
    "            best_model = model\n",
    "            best_lr = lr\n",
    "            best_batch_size = batch_size\n",
    "print (' ')          \n",
    "print(\"best loss: \", best_loss, 'best lr', best_lr, 'best batch sz', best_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss curves for hyperparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_data(plotting_data, title_str=\"Hyperparameter tuning for Inception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_data_v2(plotting_data, title_str=\"Hyperparameter tuning for Inception\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train best model for full epoch, get final val & train accuracy, plot loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best_lr, best_batch_size\n",
    "lr = best_lr\n",
    "batch_size = best_batch_size\n",
    "\n",
    "# load data\n",
    "loader_val = get_loader(val_directory, batch_size)\n",
    "loader_train = get_loader(train_directory, batch_size)\n",
    "\n",
    "# set up inception model with custom final FC layer to predict our number of classes\n",
    "model = models.inception_v3(pretrained=True)\n",
    "model.aux_logit=False\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# run for full epoch\n",
    "num_epochs = 1\n",
    "iters, losses = train(model, optimizer, loader_train, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final accuracies\n",
    "print ('validation accuracy is ', check_accuracy(loader_val, model))\n",
    "print ('training accuracy is ', check_accuracy(loader_train, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss for fully trained best model\n",
    "plot_single_loss(iters, losses, 'Loss for tuned Inception model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
